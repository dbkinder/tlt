<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Intel® Transfer Learning Tool CLI Examples &mdash; Intel® Transfer Learning Tool 0.2.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/tlt-custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Intel® Transfer Learning Tool
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Documentation Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../GetStarted.html">Get Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Models.html">Supported Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../DATASETS.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.html">Distributed Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cli.html">CLI Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docbuild.html">Building Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Legal.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/IntelAI/transfer-learning-tool">GitHub Repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Intel® Transfer Learning Tool</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Intel® Transfer Learning Tool CLI Examples</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/examples/cli/README.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="intel-transfer-learning-tool-cli-examples">
<h1>Intel® Transfer Learning Tool CLI Examples<a class="headerlink" href="#intel-transfer-learning-tool-cli-examples" title="Permalink to this heading">¶</a></h1>
<p>The following example walks through a full workflow using the Intel Transfer Learning
Tool CLI to train a model, and then benchmark, quantize, and optimize the
trained model. It uses a TensorFlow image classification model, but the
same commands and concepts can be applied when working with other frameworks
and use cases.</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">--help</span></code> to see the list of CLI commands. More detailed information on
each command can be found using <code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">&lt;command&gt;</span> <span class="pre">--help</span></code> (like <code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">train</span> <span class="pre">--help</span></code>).</p>
<p><strong>List the available models</strong>:
Use the <code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">list</span></code> command to see a list of available models for each framework.
Use the <code class="docutils literal notranslate"><span class="pre">--use-case</span></code> flag to limit the list to models for a particular use case.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tlt</span> <span class="nb">list</span> <span class="n">models</span> <span class="o">--</span><span class="n">use</span><span class="o">-</span><span class="n">case</span> <span class="n">image_classification</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">------------------------------</span>
<span class="n">IMAGE</span> <span class="n">CLASSIFICATION</span>
<span class="o">------------------------------</span>
<span class="n">alexnet</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">convnext_base</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">convnext_large</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">convnext_small</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">convnext_tiny</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">densenet121</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">densenet161</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">densenet169</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">densenet201</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">efficientnet_b0</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">efficientnet_b0</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnet_b1</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">efficientnet_b1</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnet_b2</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">efficientnet_b2</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnet_b3</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">efficientnet_b3</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnet_b4</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">efficientnet_b4</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnet_b5</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">efficientnet_b5</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnet_b6</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">efficientnet_b6</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnet_b7</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">efficientnet_b7</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnetv2</span><span class="o">-</span><span class="n">b0</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnetv2</span><span class="o">-</span><span class="n">b1</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnetv2</span><span class="o">-</span><span class="n">b2</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnetv2</span><span class="o">-</span><span class="n">b3</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">efficientnetv2</span><span class="o">-</span><span class="n">s</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">googlenet</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">inception_v3</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">mnasnet0_5</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">mnasnet1_0</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">mobilenet_v2</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="n">mobilenet_v2_100_224</span> <span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="n">mobilenet_v3_large</span> <span class="p">(</span><span class="n">pytorch</span><span class="p">)</span>
<span class="o">...</span>
</pre></div>
</div>
<p><strong>Train a model</strong>:
For this example, we use the TensorFlow flowers dataset. First, we download and extract the dataset:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># Create a directory for the dataset to be downloaded
DATASET_DIR=/tmp/dataset
mkdir -p ${DATASET_DIR}

# Download and extract the dataset
wget -P ${DATASET_DIR} https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz
tar -xzf ${DATASET_DIR}/flower_photos.tgz -C ${DATASET_DIR}

# Set the DATASET_DIR to the extracted images folder
DATASET_DIR=${DATASET_DIR}/flower_photos
</pre></div>
</div>
<p>After the dataset directory is ready, use the <code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">train</span></code> command to train one of the models from
<code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">list</span></code>. In this example, we use the TensorFlow ResNet50v1.5 model. Make sure to specify
your own file path for the <code class="docutils literal notranslate"><span class="pre">output-dir</span></code>, and the <code class="docutils literal notranslate"><span class="pre">dataset-dir</span></code> should point to the extracted dataset folder.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>tlt train -f tensorflow --model-name resnet_v1_50 --dataset-dir ${DATASET_DIR} --output-dir /tmp/output
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Model</span> <span class="n">name</span><span class="p">:</span> <span class="n">resnet_v1_50</span>
<span class="n">Framework</span><span class="p">:</span> <span class="n">tensorflow</span>
<span class="n">Training</span> <span class="n">epochs</span><span class="p">:</span> <span class="mi">1</span>
<span class="n">Dataset</span> <span class="nb">dir</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">dataset</span><span class="o">/</span><span class="n">flower_photos</span>
<span class="n">Output</span> <span class="n">directory</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">output</span>
<span class="n">Found</span> <span class="mi">3670</span> <span class="n">files</span> <span class="n">belonging</span> <span class="n">to</span> <span class="mi">5</span> <span class="n">classes</span><span class="o">.</span>
<span class="o">...</span>
<span class="n">Model</span><span class="p">:</span> <span class="s2">&quot;sequential&quot;</span>
<span class="n">_________________________________________________________________</span>
<span class="n">Layer</span> <span class="p">(</span><span class="nb">type</span><span class="p">)</span>                <span class="n">Output</span> <span class="n">Shape</span>              <span class="n">Param</span> <span class="c1">#</span>
<span class="o">=================================================================</span>
<span class="n">keras_layer</span> <span class="p">(</span><span class="n">KerasLayer</span><span class="p">)</span>    <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>              <span class="mi">23561152</span>
<span class="n">dense</span> <span class="p">(</span><span class="n">Dense</span><span class="p">)</span>               <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>                 <span class="mi">10245</span>
<span class="o">=================================================================</span>
<span class="n">Total</span> <span class="n">params</span><span class="p">:</span> <span class="mi">23</span><span class="p">,</span><span class="mi">571</span><span class="p">,</span><span class="mi">397</span>
<span class="n">Trainable</span> <span class="n">params</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span><span class="mi">245</span>
<span class="n">Non</span><span class="o">-</span><span class="n">trainable</span> <span class="n">params</span><span class="p">:</span> <span class="mi">23</span><span class="p">,</span><span class="mi">561</span><span class="p">,</span><span class="mi">152</span>
<span class="n">_________________________________________________________________</span>
<span class="n">Checkpoint</span> <span class="n">directory</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">resnet_v1_50_checkpoints</span>
<span class="mi">86</span><span class="o">/</span><span class="mi">86</span> <span class="p">[</span><span class="o">==============================</span><span class="p">]</span> <span class="o">-</span> <span class="mi">24</span><span class="n">s</span> <span class="mi">248</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.4600</span> <span class="o">-</span> <span class="n">acc</span><span class="p">:</span> <span class="mf">0.8438</span>
<span class="n">Saved</span> <span class="n">model</span> <span class="n">directory</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">resnet_v1_50</span><span class="o">/</span><span class="mi">1</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">train</span></code> command evaluates the model after training completes. The loss and
accuracy values are printed toward the end of the console output, along with the
location where the trained model has been saved.</p>
<p>A trained model can also be evaluated using the <code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">eval</span></code> command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>tlt eval --model-dir /tmp/output/resnet_v1_50/1 --dataset-dir ${DATASET_DIR}
</pre></div>
</div>
<p><strong>Benchmark the trained model</strong>:
Benchmark the performance of the trained model using <code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">benchmark</span></code>.
Make sure to specify your own file paths for <code class="docutils literal notranslate"><span class="pre">model-dir</span></code> and the <code class="docutils literal notranslate"><span class="pre">dataset-dir</span></code> should point to the extracted dataset folder.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>tlt benchmark --model-dir /tmp/output/resnet_v1_50/1 --dataset-dir ${DATASET_DIR} --batch-size 512 --mode performance
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Model</span> <span class="n">directory</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">resnet_v1_50</span><span class="o">/</span><span class="mi">1</span>
<span class="n">Dataset</span> <span class="n">directory</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">dataset</span><span class="o">/</span><span class="n">flower_photos</span>
<span class="n">Benchmarking</span> <span class="n">mode</span><span class="p">:</span> <span class="n">performance</span>
<span class="n">Batch</span> <span class="n">size</span><span class="p">:</span> <span class="mi">512</span>
<span class="n">Model</span> <span class="n">name</span><span class="p">:</span> <span class="n">resnet_v1_50</span>
<span class="n">Framework</span><span class="p">:</span> <span class="n">tensorflow</span>
<span class="o">...</span>
<span class="n">performance</span> <span class="n">mode</span> <span class="n">benchmark</span> <span class="n">result</span><span class="p">:</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">28</span> <span class="mi">10</span><span class="p">:</span><span class="mi">22</span><span class="p">:</span><span class="mi">10</span> <span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">Batch</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">28</span> <span class="mi">10</span><span class="p">:</span><span class="mi">22</span><span class="p">:</span><span class="mi">10</span> <span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">Latency</span><span class="p">:</span> <span class="mf">3.031</span> <span class="n">ms</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">28</span> <span class="mi">10</span><span class="p">:</span><span class="mi">22</span><span class="p">:</span><span class="mi">10</span> <span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">Throughput</span><span class="p">:</span> <span class="mf">329.878</span> <span class="n">images</span><span class="o">/</span><span class="n">sec</span>
</pre></div>
</div>
<p><strong>Quantize the model</strong>:
Perform post-training quantization using the <a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor</a>
using the <code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">quantize</span></code> command. Make sure to specify your own file paths for <code class="docutils literal notranslate"><span class="pre">model-dir</span></code>, <code class="docutils literal notranslate"><span class="pre">dataset-dir</span></code>, and <code class="docutils literal notranslate"><span class="pre">output-dir</span></code>.
The quantized model will be saved to the output directory.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>tlt quantize --model-dir /tmp/output/resnet_v1_50/1 --dataset-dir ${DATASET_DIR} --batch-size 512 \
--accuracy-criterion 0.01 --output-dir /tmp/output
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Model directory: /tmp/output/resnet_v1_50/1
Dataset directory: /tmp/dataset/flower_photos
Accuracy criterion: 0.01
Exit policy timeout: 0
Exit policy max trials: 50
Batch size: 512
Output directory: /tmp/output
...
2022-06-28 10:25:58 [INFO] |******Mixed Precision Statistics*****|
2022-06-28 10:25:58 [INFO] +-----------------+----------+--------+
2022-06-28 10:25:58 [INFO] |     Op Type     |  Total   |  INT8  |
2022-06-28 10:25:58 [INFO] +-----------------+----------+--------+
2022-06-28 10:25:58 [INFO] |      Conv2D     |    53    |   53   |
2022-06-28 10:25:58 [INFO] |      MatMul     |    1     |   1    |
2022-06-28 10:25:58 [INFO] |     MaxPool     |    4     |   4    |
2022-06-28 10:25:58 [INFO] |    QuantizeV2   |    5     |   5    |
2022-06-28 10:25:58 [INFO] |    Dequantize   |    4     |   4    |
2022-06-28 10:25:58 [INFO] +-----------------+----------+--------+
2022-06-28 10:25:58 [INFO] Pass quantize model elapsed time: 32164.27 ms
2022-06-28 10:25:58 [INFO] Start to evaluate the TensorFlow model.
2022-06-28 10:26:12 [INFO] Model inference elapsed time: 13921.64 ms
2022-06-28 10:26:12 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 0.9008|0.9022, Duration (seconds) (int8|fp32): 13.9226|17.3321], Best tune result is: [Accuracy: 0.9008, Duration (seconds): 13.9226]
2022-06-28 10:26:12 [INFO] |**********************Tune Result Statistics**********************|
2022-06-28 10:26:12 [INFO] +--------------------+----------+---------------+------------------+
2022-06-28 10:26:12 [INFO] |     Info Type      | Baseline | Tune 1 result | Best tune result |
2022-06-28 10:26:12 [INFO] +--------------------+----------+---------------+------------------+
2022-06-28 10:26:12 [INFO] |      Accuracy      | 0.9022   |    0.9008     |     0.9008       |
2022-06-28 10:26:12 [INFO] | Duration (seconds) | 17.3321  |    13.9226    |     13.9226      |
2022-06-28 10:26:12 [INFO] +--------------------+----------+---------------+------------------+
2022-06-28 10:26:12 [INFO] Save tuning history to /tmp/output/nc_workspace/./history.snapshot.
2022-06-28 10:26:12 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.
..
INFO:tensorflow:SavedModel written to: /tmp/output/quantized/resnet_v1_50/1/saved_model.pb
2022-06-28 10:26:13 [INFO] SavedModel written to: /tmp/output/quantized/resnet_v1_50/1/saved_model.pb
2022-06-28 10:26:13 [INFO] Save quantized model to /tmp/output/quantized/resnet_v1_50/1
</pre></div>
</div>
<p><strong>Benchmark the quantized model</strong>:
The <code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">benchmark</span></code> command is used again, but this time the <code class="docutils literal notranslate"><span class="pre">model-dir</span></code> should point
to the quantized model directory.
Make sure to specify your own file paths for <code class="docutils literal notranslate"><span class="pre">model-dir</span></code> and <code class="docutils literal notranslate"><span class="pre">dataset-dir</span></code>. You can then compare
the performance of the full precision model to the quantized model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>tlt benchmark --model-dir /tmp/output/quantized/resnet_v1_50/1 --dataset-dir ${DATASET_DIR} --batch-size 512 --mode performance
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Model</span> <span class="n">directory</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">quantized</span><span class="o">/</span><span class="n">resnet_v1_50</span><span class="o">/</span><span class="mi">1</span>
<span class="n">Dataset</span> <span class="n">directory</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">dataset</span><span class="o">/</span><span class="n">flower_photos</span>
<span class="n">Benchmarking</span> <span class="n">mode</span><span class="p">:</span> <span class="n">performance</span>
<span class="n">Batch</span> <span class="n">size</span><span class="p">:</span> <span class="mi">512</span>
<span class="n">Model</span> <span class="n">name</span><span class="p">:</span> <span class="n">resnet_v1_50</span>
<span class="n">Framework</span><span class="p">:</span> <span class="n">tensorflow</span>
<span class="o">...</span>
<span class="n">performance</span> <span class="n">mode</span> <span class="n">benchmark</span> <span class="n">result</span><span class="p">:</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">28</span> <span class="mi">10</span><span class="p">:</span><span class="mi">28</span><span class="p">:</span><span class="mi">33</span> <span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">Batch</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">28</span> <span class="mi">10</span><span class="p">:</span><span class="mi">28</span><span class="p">:</span><span class="mi">33</span> <span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">Latency</span><span class="p">:</span> <span class="mf">0.946</span> <span class="n">ms</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">28</span> <span class="mi">10</span><span class="p">:</span><span class="mi">28</span><span class="p">:</span><span class="mi">33</span> <span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">Throughput</span><span class="p">:</span> <span class="mf">1056.940</span> <span class="n">images</span><span class="o">/</span><span class="n">sec</span>
</pre></div>
</div>
<p><strong>Perform graph optimization on the trained model</strong>:
Alternatively, the <a class="reference external" href="https://github.com/intel/neural-compressor">Intel Neural Compressor</a> can be used to optimize
the full precision graph. Make sure to specify your own file paths for <code class="docutils literal notranslate"><span class="pre">model-dir</span></code> and <code class="docutils literal notranslate"><span class="pre">output-dir</span></code>.
Note that graph optimization is also done as part of the quantization flow, so there is no need to call
<code class="docutils literal notranslate"><span class="pre">tlt</span> <span class="pre">optimize</span></code> on a quantized model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tlt</span> <span class="n">optimize</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="nb">dir</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">resnet_v1_50</span><span class="o">/</span><span class="mi">1</span> <span class="o">--</span><span class="n">output</span><span class="o">-</span><span class="nb">dir</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">output</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Model</span> <span class="n">directory</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">resnet_v1_50</span><span class="o">/</span><span class="mi">1</span>
<span class="n">Model</span> <span class="n">name</span><span class="p">:</span> <span class="n">resnet_v1_50</span>
<span class="n">Output</span> <span class="n">directory</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">output</span>
<span class="n">Framework</span><span class="p">:</span> <span class="n">tensorflow</span>
<span class="n">Starting</span> <span class="n">graph</span> <span class="n">optimization</span>
<span class="o">...</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">28</span> <span class="mi">13</span><span class="p">:</span><span class="mi">50</span><span class="p">:</span><span class="mi">01</span> <span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">Graph</span> <span class="n">optimization</span> <span class="ow">is</span> <span class="n">done</span><span class="o">.</span>
<span class="o">...</span>
<span class="mi">2022</span><span class="o">-</span><span class="mi">06</span><span class="o">-</span><span class="mi">28</span> <span class="mi">13</span><span class="p">:</span><span class="mi">51</span><span class="p">:</span><span class="mi">21</span> <span class="p">[</span><span class="n">INFO</span><span class="p">]</span> <span class="n">SavedModel</span> <span class="n">written</span> <span class="n">to</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">optimized</span><span class="o">/</span><span class="n">resnet_v1_50</span><span class="o">/</span><span class="mi">1</span><span class="o">/</span><span class="n">saved_model</span><span class="o">.</span><span class="n">pb</span>
</pre></div>
</div>
<p>More CLI examples can be found here:</p>
<ul class="simple">
<li><p><a class="reference internal" href="image_classification.html"><span class="doc std std-doc">Image classification examples</span></a></p></li>
<li><p><a class="reference internal" href="text_classification.html"><span class="doc std std-doc">Text classification examples</span></a></p></li>
</ul>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2023, Intel Corporation.
      <span class="lastupdated">Last updated on May 24, 2023.
      </span></p>
  </div>

  
*Other names and brands may be claimed as the property of others.
<a href="http://www.intel.com/content/www/us/en/legal/trademarks.html">Trademarks</a>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>